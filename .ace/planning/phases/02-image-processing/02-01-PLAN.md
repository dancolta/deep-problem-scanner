# Plan: Annotation Detection & Image Processing Pipeline

**Phase:** 2 - Image Processing & Annotation Pipeline
**Plan:** 1 of 1 in phase
**Status:** Ready

## Objective

Build the full annotation pipeline: send screenshots to Gemini Pro Vision for problem detection with coordinate mapping, draw red boxes and labels on screenshots using Sharp, and compress the final PNG to <100KB.

## Tasks

### Task 1: Gemini Pro Vision Integration (Annotation Coordinate Detection)
**Zone:** ALPHA
**Files:**
- `src/services/annotation/gemini-vision.ts`
- `src/services/annotation/types.ts`

**Action:**
1. Create `src/services/annotation/types.ts`:
   - `AnnotationSeverity`: 'critical' | 'warning' | 'info'
   - `AnnotationCoord`: { x: number, y: number, width: number, height: number, label: string, severity: AnnotationSeverity, description: string }
   - `AnnotationResult`: { annotations: AnnotationCoord[], rawAnalysis: string, problemCount: number }
   - `AnnotationOptions`: { maxAnnotations: number, screenshotWidth: number, screenshotHeight: number }

2. Create `src/services/annotation/gemini-vision.ts`:
   - Import `GoogleGenerativeAI` from `@google/generative-ai`
   - `detectAnnotations(screenshotBuffer: Buffer, diagnostics: DiagnosticResult[], url: string, options?: Partial<AnnotationOptions>): Promise<AnnotationResult>`
   - Convert screenshot Buffer to base64 for Gemini input
   - Build a structured prompt that:
     - Provides the screenshot as an image
     - Includes the 5 diagnostic results for context
     - Asks Gemini to identify the TOP 3-5 most impactful visual problems
     - Requests precise pixel coordinates (x, y, width, height) for each problem on the 1440x900 screenshot
     - Specifies JSON output format: `{ annotations: [{ x, y, width, height, label, severity, description }] }`
     - Labels should be SHORT (2-4 words): "No CTA Button", "Slow Load Time", "Missing H1", "No Mobile Meta", "Broken Link"
   - Parse Gemini's JSON response with error handling (regex fallback if JSON is embedded in text)
   - Validate coordinates are within screenshot bounds (0-1440, 0-900)
   - Clamp any out-of-bounds coordinates to valid range
   - Default max 5 annotations
   - Use `gemini-1.5-pro` model (supports vision)

**Verify:**
- [ ] Types are exported and well-defined
- [ ] Gemini Vision API call is properly structured with image + prompt
- [ ] JSON response parsing handles both clean JSON and JSON-in-text
- [ ] Coordinate validation clamps to screenshot dimensions
- [ ] TypeScript compiles without errors

**Done when:**
`detectAnnotations()` accepts a screenshot Buffer + diagnostics, calls Gemini Pro Vision, and returns validated annotation coordinates with labels and severity.

---

### Task 2: Sharp Drawing Engine (Red Boxes + Labels)
**Zone:** BETA
**Files:**
- `src/services/annotation/drawing.ts`

**Action:**
1. Create `src/services/annotation/drawing.ts`:
   - `drawAnnotations(screenshotBuffer: Buffer, annotations: AnnotationCoord[]): Promise<Buffer>`
   - For each annotation, create two SVG overlays to composite onto the image:

   **a) Red rectangle border:**
   - Use Sharp's composite with an SVG overlay
   - Draw a red (#e94560) rectangle border (3px stroke, no fill) at the annotation coordinates
   - Slight rounded corners (4px border-radius)

   **b) Label badge:**
   - Red (#e94560) pill-shaped background rectangle positioned at top-left of the annotation box
   - White text (#ffffff) inside, bold, 14px font
   - Padding: 4px vertical, 8px horizontal
   - Position label just above the annotation box (offset y - 24px), or below if near top edge

   **Implementation approach:**
   - Generate a single SVG string containing ALL annotation rectangles and labels
   - Use Sharp's `.composite([{ input: Buffer.from(svgString), top: 0, left: 0 }])` to overlay in one pass
   - SVG should be the same dimensions as the screenshot (1440x900)
   - Handle overlapping annotations: offset labels that would overlap
   - Handle edge cases: annotations near image borders (shift labels inward)

   **Severity-based colors (optional enhancement):**
   - critical: #e94560 (red)
   - warning: #f59e0b (amber)
   - info: #3b82f6 (blue)

**Verify:**
- [ ] SVG overlay renders rectangles with proper coordinates
- [ ] Labels are readable with white text on colored backgrounds
- [ ] Edge-case handling for annotations near borders
- [ ] Output is a valid PNG Buffer
- [ ] TypeScript compiles without errors

**Done when:**
`drawAnnotations()` takes a screenshot Buffer and annotation coordinates, composites red boxes and labels via SVG overlay using Sharp, and returns the annotated image as a PNG Buffer.

---

### Task 3: Compression Pipeline & Annotation Service Orchestrator
**Zone:** GAMMA
**Files:**
- `src/services/annotation/compression.ts`
- `src/services/annotation/annotation-service.ts`

**Action:**
1. Create `src/services/annotation/compression.ts`:
   - `compressImage(imageBuffer: Buffer, maxSizeKB: number): Promise<Buffer>`
   - Step 1: Apply Sharp PNG compression with effort level 10 (max compression), palette-based quantization
   - Step 2: Check file size. If > maxSizeKB:
     - Reduce image dimensions by 10% increments (resize width, maintain aspect ratio)
     - Re-compress after each resize
     - Repeat until under limit or minimum width (800px) reached
   - Step 3: If still over limit after min width, switch to JPEG at quality 70 as last resort
   - Return final compressed buffer
   - `getImageInfo(buffer: Buffer): Promise<{ width: number, height: number, sizeKB: number, format: string }>`
   - Helper to inspect image buffer metadata

2. Create `src/services/annotation/annotation-service.ts`:
   - `AnnotationService` class that orchestrates the full pipeline:
     - `annotateScreenshot(screenshotBuffer: Buffer, diagnostics: DiagnosticResult[], url: string, companySlug: string): Promise<AnnotatedImage>`
     - Pipeline steps:
       1. Call `detectAnnotations()` (Gemini Vision) to get coordinates
       2. Call `drawAnnotations()` (Sharp) to render boxes/labels
       3. Call `compressImage()` to compress to <100KB
       4. Generate filename: `{companySlug}_homepage_scan_{YYYY-MM-DD}.png`
       5. Return `AnnotatedImage` with buffer, filename, metadata
   - `AnnotatedImage` interface: { buffer: Buffer, filename: string, sizeKB: number, format: string, annotationCount: number, width: number, height: number }
   - Handle pipeline failures gracefully:
     - If Gemini Vision fails: return screenshot with NO annotations (still compress)
     - If drawing fails: return screenshot with NO annotations (still compress)
     - If compression fails: return original screenshot with warning
   - `generateCompanySlug(companyName: string): string`
     - Lowercase, replace spaces/special chars with hyphens, truncate to 50 chars

**Verify:**
- [ ] Compression achieves <100KB on typical 1440x900 screenshots
- [ ] Dimension reduction kicks in when compression alone isn't enough
- [ ] Annotation service chains all 3 steps correctly
- [ ] Graceful degradation when any pipeline step fails
- [ ] Filename format matches `{slug}_homepage_scan_{date}.png`
- [ ] TypeScript compiles without errors

**Done when:**
Full pipeline works: screenshot → Gemini Vision → Sharp drawing → compression → named file. `AnnotationService.annotateScreenshot()` returns a compressed, annotated PNG under 100KB with proper filename.

---

## Checkpoints

None - fully autonomous execution.

## Success Criteria

- [ ] All tasks completed
- [ ] All verifications pass
- [ ] Gemini Vision returns valid annotation coordinates from screenshots
- [ ] Sharp draws red boxes and labels correctly
- [ ] Final images are <100KB PNG
- [ ] Pipeline degrades gracefully on failures
- [ ] TypeScript compiles without errors
